{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 4 Mathematics and Programming in Artificail intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Why CIFAR-10](#why-cifar-10)\n",
    "2. Task 1: NumPy Neural Network Implementation\n",
    "   - [Activation Functions](#Activation-Functions)\n",
    "   - [Softmax Layer](#Softmax-Layer)\n",
    "   - [Dropout Implementation](#Dropout-Implementation)\n",
    "   - [Neural Network Class](#neural-network-class)\n",
    "   - [Optimisers](#optimisers)\n",
    "   - [Network Evaluation and Results](#network-evaluation-and-results)\n",
    "3. Task 2: PyTorch Implementation\n",
    "   - [Dataset Preparation](#dataset-preparation)\n",
    "   - [Model Description and Implementation](#model-description-and-implementation)\n",
    "   - [Improvements](#improvements)\n",
    "   - [Hyperparameter Optimisation](#hyperparameter-optimisation)\n",
    "   - [Results and Discussion](#results-and-discussion)\n",
    "4. [Conclusion and Reflection](#conclusion-and-reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose CIFAR-10 dataset due to its complexity and suitability in evaluating multi-layer neural networks. It holds 60,000 32x32 colour images spanning 10 diverse classes, crescendoing in a challenging classification task surpassing the likes of datasets like MNIST, which only holds grayscale digits. CIFAR-10 includes RGB images, demanding models to learn from more detailed and complex data, mirroring real world applications, where data is diverse and high dimensional. The aforementioned complexity allows rigorous testing of network architectures, activation functions, and techniques to optimise the model. Lastly, it has well documented benchmarks, and  widespread use in academic research making it a top candidate to showcase advanced implementations, setting the ground work for meaningful comparisons and evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: NumPy Neural Network Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    @staticmethod\n",
    "    def sigmoidForward(x):\n",
    "        '''\n",
    "        this function does the forward pass of the sigmoid function\n",
    "        it takes an input array i just called x \n",
    "        and it returns a tuple with the result (out) of the sigmoid function\n",
    "        as well as cache which we use in the backward pass, its just the same as the out \n",
    "        '''\n",
    "        out = 1/ (1+ np.exp(-x)) #the sigmoid function\n",
    "        cache = out \n",
    "        return out, cache\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoidBackward(dout, cache):\n",
    "        '''\n",
    "        does the backward pass of the simoid function\n",
    "        i used d to show that its the derivative \n",
    "        so dx is the gradient of the loss with resepct to x (the input array)\n",
    "        dout is the upstream gradient\n",
    "        sig is just the sigmoid function hence why it equals cache\n",
    "        '''\n",
    "        sig = cache\n",
    "        dx = dout * sig * (1 - sig) #the derivative of the sigmoid function multiplied by the upstream gradient to get the proper flow of gradients\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    @staticmethod   \n",
    "    def reluForward(x):\n",
    "        '''\n",
    "        does the forward pass of the ReLU function\n",
    "        x is the input arry \n",
    "        and then it outputs a tuple with the result of the  ReLU forward pass as well a cache used for backward pass\n",
    "        cache this time is the input array \n",
    "        '''\n",
    "        out = np.maximum(0,x)\n",
    "        cache = x \n",
    "        return out, cache\n",
    "    @staticmethod\n",
    "    def reluBackward(dout, cache):\n",
    "        '''\n",
    "        backward pass of the ReLU function\n",
    "        x is just passing on the inpui arrat from forward pass using cache as the temporary store \n",
    "        dx is the gradient of the loss in respect to the input (being the array x)\n",
    "        dout is the upstream gradient \n",
    "        '''\n",
    "        x = cache \n",
    "        dx = dout * (x > 0) #derivative is 1 when x >0 otherwise it is 0\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self):\n",
    "        # Prepare to store the output of the softmax function\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, logits):\n",
    "        \"\"\"\n",
    "        Perform the forward pass to calculate softmax probabilities.\n",
    "        \n",
    "        Parameters:\n",
    "        logits (np.array): Scores from the previous layer, shaped (batch_size, num_classes).\n",
    "\n",
    "        Returns:\n",
    "        np.array: Probabilities for each class, same shape as input.\n",
    "        \"\"\"\n",
    "        # Subtract the max to keep numbers stable\n",
    "        z_max = np.max(logits, axis=1, keepdims=True)\n",
    "        shifted_logits = logits - z_max\n",
    "        exp_shifted = np.exp(shifted_logits)\n",
    "\n",
    "        # Divide by sum of exponents to get probabilities\n",
    "        sum_exp = np.sum(exp_shifted, axis=1, keepdims=True)\n",
    "        self.output = exp_shifted / sum_exp\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, true_labels):\n",
    "        \"\"\"\n",
    "        Perform the backward pass to calculate gradient of the loss.\n",
    "        \n",
    "        Parameters:\n",
    "        true_labels (np.array): One-hot encoded true class labels.\n",
    "\n",
    "        Returns:\n",
    "        np.array: Gradient of the loss with respect to logits.\n",
    "        \"\"\"\n",
    "        # Get the number of samples to average the gradient\n",
    "        num_samples = true_labels.shape[0]\n",
    "\n",
    "        # Calculate the gradient for softmax combined with cross-entropy\n",
    "        gradient = (self.output - true_labels) / num_samples\n",
    "        return gradient\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage of SoftmaxLayer\n",
    "\n",
    "    # Define example logits, representing class scores\n",
    "    logits_example = np.array([[2.0, 1.0, 0.1],\n",
    "                               [1.0, 2.0, 0.1]])\n",
    "\n",
    "    # Define the true labels in one-hot encoding\n",
    "    true_labels_example = np.array([[1, 0, 0],\n",
    "                                    [0, 1, 0]])\n",
    "\n",
    "    # Instantiate the softmax layer\n",
    "    softmax_layer = SoftmaxLayer()\n",
    "\n",
    "    # Forward pass to get probability distributions\n",
    "    softmax_output = softmax_layer.forward(logits_example)\n",
    "    print(\"Softmax Probabilities:\\n\", softmax_output)\n",
    "\n",
    "    # Backward pass to compute gradient\n",
    "    loss_gradient = softmax_layer.backward(true_labels_example)\n",
    "    print(\"Gradient of Loss w.r.t Logits:\\n\", loss_gradient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    \"\"\"\n",
    "    Author: Abdelrahmane Bekhli\n",
    "    Date: 2024-11-18\n",
    "    Description: This class performs dropouts.\n",
    "    \"\"\"\n",
    "    def __init__(self, dropoutRate, seed=None):\n",
    "        \"\"\" \n",
    "        Initialize the Dropout layer. \n",
    "        Args: \n",
    "            dropoutRate (float): The probability of dropping out a unit. \n",
    "            seed (int, optional): Random seed for reproducibility. \n",
    "        \"\"\"\n",
    "        if not (0 <= dropoutRate < 1):\n",
    "            raise ValueError(\"Dropout rate must be between 0 and 1\")\n",
    "        self.dropoutRate = dropoutRate\n",
    "        self.mask = None\n",
    "        self.training = True\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for dropout.\n",
    "        Args:\n",
    "            x (numpy array): The input to the dropout layer.\n",
    "        Returns:\n",
    "            numpy array: Output after applying dropout.\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropoutRate\n",
    "            return x * self.mask / (1 - self.dropoutRate)\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        Backward pass for dropout.\n",
    "        Args:\n",
    "            dout (numpy array): The gradient from the next layer.\n",
    "        Returns:\n",
    "            numpy array: Gradient after applying dropout mask.\n",
    "        \"\"\"\n",
    "        return dout * self.mask / (1 - self.dropoutRate)\n",
    "    \n",
    "    def setMode(self, mode):\n",
    "        \"\"\"\n",
    "        Set the mode for the network: 'train' or 'test'\n",
    "        Args:\n",
    "            mode (str): Either 'train' or 'test'.\n",
    "        \"\"\"\n",
    "        if mode == 'train':\n",
    "            self.training = True\n",
    "        elif mode == 'test':\n",
    "            self.training = False\n",
    "        else:\n",
    "            raise ValueError(\"Mode can only be 'train' or 'test'\")\n",
    "        self.mask = None # reset mask when changing modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: PyTorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description and Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:51<00:00, 3.29MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Check if a GPU is open, if it is use CUDA for faster computation, if not go with CPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Randomly crop a patch that is 32x32 with padding, improving robustness to spatial shifts\n",
    "    transforms.RandomHorizontalFlip(),  # Flip the image horizontally to augment data \n",
    "    transforms.ToTensor(),  # Convert from PIL to PyTorch tensors format\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Add color jitter to simulate varied lighting conditions\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to have a mean of 0.5 and std of 0.5 for stability\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Only normalize test data; augmentation not needed during evaluation\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset with the specified transformations\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# train/validation split ratio\n",
    "train_size = int(0.8 * len(train_data))  # 80% for training\n",
    "validation_size = len(train_data) - train_size  # 20% for validation\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "train_data, validation_data = random_split(train_data, [train_size, validation_size])\n",
    "\n",
    "# Create data loaders for train, validation, and test sets\n",
    "load_train = DataLoader(train_data, batch_size=64, shuffle=True)  # Training data is in random order to help training\n",
    "load_val = DataLoader(validation_data, batch_size=64, shuffle=False)  # No shuffling for validation data\n",
    "load_test = DataLoader(test_data, batch_size=64, shuffle=False)  # No shuffling for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# defining model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        #convolutional layers \n",
    "        self.convolution1 = nn.Conv2d(3,32, kernel_size= 3, padding = 1) #conv2d applies 2d convolution\n",
    "        self.normaliseBatch1 = nn.BatchNorm2d(32) #normalise each batch activation to have training be stable and speed up convergence \n",
    "        self.convolution2 = nn.Conv2d(32,64, kernel_size= 3, padding =1)\n",
    "        self.normaliseBatch2 = nn.BatchNorm2d(64)\n",
    "        self.convolution3 = nn.Conv2d(64,128, kernel_size=3, padding =1)\n",
    "        self.normaliseBatch3 = nn.BatchNorm2d(128)\n",
    "    \n",
    "        self.pool = nn.MaxPool2d(2,2) #reduce dimensions, takes the max value in a 2 by 2 window, halves the width and heigth\n",
    "        # fully connected layer \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256) #input flattend output from last convolutional layer \n",
    "        self.fc2 = nn.Linear(256, 10) # output 256 in the first layer, 10 in the last \n",
    "        self.dropout = nn.Dropout(0.5) #randomly deactive half the neurons as to not oevrfit \n",
    "        self.relu = nn.ReLU() # apply activation fucntuion relu \n",
    "\n",
    "    def forward(self, x):\n",
    "        #the following three functions normalise activations, make it non-linear, reduce spatial dimension\n",
    "        x = self.pool(self.relu(self.normaliseBatch1(self.convolution1(x)))) \n",
    "        x = self.pool(self.relu(self.normaliseBatch2(self.convolution2(x))))\n",
    "        x = self.pool(self.relu(self.normaliseBatch3(self.convolution3(x))))\n",
    "        x = x.view(-1, 128 * 4 * 4)  # 2d features to 1d for fully connected layers\n",
    "        x = self.dropout(self.relu(self.fc1(x)))  #regularsing the flattened output after beiong passed through the first fully connected layer\n",
    "        x = self.fc2(x) #passes the output through the second fully connnected layer to get class score \n",
    "        return x #the raw prediction scores for each class in the dataaset\n",
    "    \n",
    "model = CNN().to(device) #initialise and move to the device that we prepared in the above module\n",
    "criterion = nn.CrossEntropyLoss() #to get the difference between predictions and ground truth\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001) #adjusts the weights in the model based on the gradients\n",
    "\n",
    "#loop for training\n",
    "epochs = 20 #training will iterate through 20 epochs over the whole dataset\n",
    "for epoch in range(epochs): #processed training for every epoch \n",
    "    model.train() #enables training and activates dropout\n",
    "    running_loss = 0.0  #initiate the loss counter which will be used to calc the average loss\n",
    "    for inputs, labels in load_train: #loops through the branches training data we had made in the data loader above\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # move both the image tensors from the current batch, and the corresponging true class lables to the selcted device\n",
    "        optimiser.zero_grad() #reset gradient from previous iteration of training \n",
    "        outputs = model(inputs) #forward pass, feeds input through the cnn, generating predictions for the batch\n",
    "        loss = criterion(outputs, labels) #calculating the loss function between predictions and labels using cross entropy loss \n",
    "        loss.backward() #back propagation gives us the gradient \n",
    "        optimiser.step() #update the parameters using the calculated gradient\n",
    "        running_loss += loss.item() #keeps track of the average loss per epoch \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(load_train):.4f}\") #output the current average loss for the epoch\n",
    "\n",
    "model.eval() #switch from training to evaluation\n",
    "#initialise the metrics\n",
    "correct = 0  #correct classifiers\n",
    "total = 0 #number of imaged evaluated\n",
    "with torch.no_grad(): #to save some memory prevent gradient computation while inference is running \n",
    "    for inputs, labels in load_test: #go through test set\n",
    "        inputs, labels = inputs.to(device), labels.to(device) #move the images and corresponding lables to the device selected\n",
    "        outputs = model(inputs) #forward pass inputs into the cnn model, giving us a tensor with the raw prediction scores from the final layer\n",
    "        _, predicted = torch.max(outputs, 1) #choose the class with the higherst prediction score, return the predicted class index, the maximum vaye itseld is not used.\n",
    "        total += labels.size(0) #increase total by number of images in the batch to keep track of the ones processed\n",
    "        correct += (predicted == labels).sum().item() #compare prediction with labels\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\") #prints out the calculated accuracy % to 2 decimal places\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
